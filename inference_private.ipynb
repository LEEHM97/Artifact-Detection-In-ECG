{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 재시작 없이 import 파일 자동 적용\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Private Test Set - Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import CONFIG\n",
    "from data_factory import collate_fn\n",
    "from data_loader import PublicTest\n",
    "from classification import Exp_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints 및 CONFIG file 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib.util\n",
    "\n",
    "# test_folder_name = 'classification_T#17_Medformer_K-Medicon_bs8_sl96_lr0.0001_pl96_dm128_nh8_el6_df256_fc1_ebtimeF_Exp_seed41'\n",
    "# test_id = test_folder_name.split('_')[1]\n",
    "# print(\"Test ID:\", test_id)\n",
    "# # test_config_path = f\"./checkpoints/{test_folder_name}/config_{test_id}.py\"\n",
    "# test_config_path = f\"./checkpoints/{test_folder_name}/config_{test_id}.py\"\n",
    "\n",
    "# # 모듈 이름 생성\n",
    "# module_name = os.path.splitext(os.path.basename(test_config_path))[0]\n",
    "\n",
    "# # 모듈 로드\n",
    "# spec = importlib.util.spec_from_file_location(module_name, test_config_path)\n",
    "# config_module = importlib.util.module_from_spec(spec)\n",
    "# spec.loader.exec_module(config_module)\n",
    "\n",
    "# # CONFIG 변수 사용\n",
    "# CONFIG = config_module.CONFIG  # config_T#01.py 파일 내의 CONFIG 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01_11\n"
     ]
    }
   ],
   "source": [
    "print(CONFIG['model_id'])\n",
    "seed = CONFIG['seed']\n",
    "    \n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "setting = \"{}_{}_{}_{}_bs{}_{}hz_{}_{}_sl{}_lr{}_pl{}_dm{}_nh{}_el{}_df{}_fc{}_eb{}_{}_{}_seed{}_{}\".format(\n",
    "                CONFIG['task_name'],\n",
    "                CONFIG['model_id'],\n",
    "                CONFIG['model'],\n",
    "                CONFIG['data'],\n",
    "                CONFIG['batch_size'],\n",
    "                CONFIG['signal_hz'],\n",
    "                CONFIG['monitor'],\n",
    "                CONFIG['loss'],\n",
    "                CONFIG['seq_len'],\n",
    "                CONFIG['learning_rate'],\n",
    "                CONFIG['pred_len'],\n",
    "                CONFIG['d_model'],\n",
    "                CONFIG['n_heads'],\n",
    "                CONFIG['e_layers'],\n",
    "                CONFIG['d_ff'],\n",
    "                CONFIG['factor'],\n",
    "                CONFIG['embed'],\n",
    "                CONFIG['activation'],\n",
    "                CONFIG['des'],\n",
    "                CONFIG['seed'],\n",
    "                CONFIG['augmentations'],\n",
    "            )\n",
    "\n",
    "exp = Exp_Classification(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pth_list = os.listdir('./private_test_pth')\n",
    "# print(len(pth_list))\n",
    "# pth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./private_test_pth/S01_11.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AveragedModel(\n",
       "  (module): Model(\n",
       "    (enc_embedding): ListPatchEmbedding(\n",
       "      (value_embeddings): ModuleList(\n",
       "        (0): CrossChannelTokenEmbedding(\n",
       "          (tokenConv): Conv2d(1, 128, kernel_size=(12, 2), stride=(1, 2), bias=False, padding_mode=circular)\n",
       "        )\n",
       "        (1): CrossChannelTokenEmbedding(\n",
       "          (tokenConv): Conv2d(1, 128, kernel_size=(12, 4), stride=(1, 4), bias=False, padding_mode=circular)\n",
       "        )\n",
       "        (2-3): 2 x CrossChannelTokenEmbedding(\n",
       "          (tokenConv): Conv2d(1, 128, kernel_size=(12, 8), stride=(1, 8), bias=False, padding_mode=circular)\n",
       "        )\n",
       "        (4-7): 4 x CrossChannelTokenEmbedding(\n",
       "          (tokenConv): Conv2d(1, 128, kernel_size=(12, 16), stride=(1, 16), bias=False, padding_mode=circular)\n",
       "        )\n",
       "        (8-15): 8 x CrossChannelTokenEmbedding(\n",
       "          (tokenConv): Conv2d(1, 128, kernel_size=(12, 32), stride=(1, 32), bias=False, padding_mode=circular)\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (augmentation): ModuleList(\n",
       "        (0): Jitter()\n",
       "        (1): Scale()\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (learnable_embeddings): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (5): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (6): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (7): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (8): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (9): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (10): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (11): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (12): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (13): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (14): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "          (15): Parameter containing: [torch.float32 of size 1x128 (GPU 0)]\n",
       "      )\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (attn_layers): ModuleList(\n",
       "        (0-5): 6 x EncoderLayer(\n",
       "          (attention): MedformerLayer(\n",
       "            (intra_attentions): ModuleList(\n",
       "              (0-15): 16 x AttentionLayer(\n",
       "                (inner_attention): FullAttention(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (query_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (out_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (inter_attention): AttentionLayer(\n",
       "              (inner_attention): FullAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (out_projection): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (conv1): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (projection): Linear(in_features=481664, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = f\"./checkpoints/{test_folder_name}/checkpoint.pth\"\n",
    "model_path = f\"./private_test_pth/{CONFIG['model_id']}.pth\"\n",
    "print(model_path)\n",
    "\n",
    "exp.swa_model.load_state_dict(torch.load(model_path))\n",
    "exp.swa_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 250 hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public label\n",
    "testset = PublicTest(\"./dataset/Signal_Test_Private_250hz.h5\")\n",
    "public_test_loader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # collate_fn=lambda x: collate_fn(\n",
    "    #             x, max_len=CONFIG['seq_len']),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "total_loss = []\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, label) in enumerate(tqdm(public_test_loader)):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        label = label.to(device)\n",
    "        # padding_mask = padding_mask.float().to(device)\n",
    "\n",
    "        outputs = exp.swa_model(batch_x, None, None, None)\n",
    "\n",
    "        pred = outputs.detach().cpu()\n",
    "\n",
    "        preds.append(outputs.detach())\n",
    "        trues.append(label)\n",
    "\n",
    "preds = torch.cat(preds, 0)\n",
    "trues = torch.cat(trues, 0)\n",
    "\n",
    "probs = torch.nn.functional.softmax(\n",
    "# probs = torch.nn.functional.sigmoid(\n",
    "    preds\n",
    ")  # (total_samples, num_classes) est. prob. for each class and sample\n",
    "\n",
    "trues_onehot = (torch.nn.functional.one_hot(trues.reshape(-1,).to(torch.long),\n",
    "                num_classes=CONFIG['num_class'],).float().cpu().numpy())\n",
    "\n",
    "print(trues_onehot.shape)\n",
    "predictions = (\n",
    "    torch.argmax(probs, dim=1).cpu().numpy()\n",
    ")  # (total_samples,) int class index for each sample\n",
    "probs = probs.cpu().numpy()\n",
    "trues = trues.flatten().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6013986013986015\n",
      "AUROC score: 0.8278518518518518\n",
      "MCC score: 0.47805103537939936\n",
      "CPI score: 0.596338131002313\n",
      "\n",
      "0개수: 232\n",
      "1개수: 68\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "f1 = f1_score(trues, predictions, average=\"binary\")\n",
    "auroc = roc_auc_score(trues_onehot, probs)\n",
    "# auroc = roc_auc_score(trues, probs)\n",
    "mcc = matthews_corrcoef(trues, predictions)\n",
    "cpi = (0.25 * f1) + (0.25 * auroc) + (0.5 * mcc)\n",
    "\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"AUROC score: {auroc}\")\n",
    "print(f\"MCC score: {mcc}\")\n",
    "print(f\"CPI score: {cpi}\")\n",
    "print()\n",
    "print(f\"0개수: {len(np.where(predictions[:]==0)[0])}\")\n",
    "print(f\"1개수: {len(np.where(predictions[:]==1)[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"0\":probs[:,0], \"1\":probs[:,1]})\n",
    "df = pd.DataFrame({\"Probability\":probs[:,1]})\n",
    "\n",
    "# save_xlsx = pd.ExcelWriter(f\"./RTFACT_Public_Possibility_{CONFIG['model_id']}.xlsx\")\n",
    "# df.to_excel(save_xlsx, index = False) # xlsx 파일로 변환\n",
    "# save_xlsx.save() #xlsx 파일로 저장\n",
    "\n",
    "# ExcelWriter 사용\n",
    "with pd.ExcelWriter(f\"../../Submission results/private/RTFACT_241014_Private_Possibility_{CONFIG['model_id']}_Softmax.xlsx\", engine='openpyxl') as writer:\n",
    "# with pd.ExcelWriter(f\"../../Submission results/private/RTFACT_241014_Private_Possibility_{CONFIG['model_id']}_Sigmoid.xlsx\", engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 500 hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Public label\n",
    "# testset = PublicTest(\"./dataset/Signal_Test_Private_500hz.h5\")\n",
    "# public_test_loader = DataLoader(\n",
    "#     testset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     drop_last=False,\n",
    "#     # collate_fn=lambda x: collate_fn(\n",
    "#     #             x, max_len=CONFIG['seq_len']),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:15<00:00, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "# total_loss = []\n",
    "# preds = []\n",
    "# trues = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, (batch_x, label) in enumerate(tqdm(public_test_loader)):\n",
    "#         batch_x = batch_x.float().to(device)\n",
    "#         label = label.to(device)\n",
    "#         # padding_mask = padding_mask.float().to(device)\n",
    "\n",
    "#         outputs = exp.swa_model(batch_x, None, None, None)\n",
    "\n",
    "#         pred = outputs.detach().cpu()\n",
    "\n",
    "#         preds.append(outputs.detach())\n",
    "#         trues.append(label)\n",
    "\n",
    "# preds = torch.cat(preds, 0)\n",
    "# trues = torch.cat(trues, 0)\n",
    "\n",
    "# probs = torch.nn.functional.softmax(\n",
    "#     preds\n",
    "# )  # (total_samples, num_classes) est. prob. for each class and sample\n",
    "\n",
    "# trues_onehot = (torch.nn.functional.one_hot(trues.reshape(-1,).to(torch.long),\n",
    "#                 num_classes=CONFIG['num_class'],).float().cpu().numpy())\n",
    "\n",
    "# print(trues_onehot.shape)\n",
    "# predictions = (\n",
    "#     torch.argmax(probs, dim=1).cpu().numpy()\n",
    "# )  # (total_samples,) int class index for each sample\n",
    "# probs = probs.cpu().numpy()\n",
    "# trues = trues.flatten().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.4968944099378882\n",
      "AUROC score: 0.7535999999999999\n",
      "MCC score: 0.3149306866445732\n",
      "CPI score: 0.47008894580675864\n",
      "\n",
      "0개수: 214\n",
      "1개수: 86\n"
     ]
    }
   ],
   "source": [
    "# # softmax\n",
    "# f1 = f1_score(trues, predictions, average=\"binary\")\n",
    "# auroc = roc_auc_score(trues_onehot, probs)\n",
    "# # auroc = roc_auc_score(trues, probs)\n",
    "# mcc = matthews_corrcoef(trues, predictions)\n",
    "# cpi = (0.25 * f1) + (0.25 * auroc) + (0.5 * mcc)\n",
    "\n",
    "# print(f\"F1 score: {f1}\")\n",
    "# print(f\"AUROC score: {auroc}\")\n",
    "# print(f\"MCC score: {mcc}\")\n",
    "# print(f\"CPI score: {cpi}\")\n",
    "# print()\n",
    "# print(f\"0개수: {len(np.where(predictions[:]==0)[0])}\")\n",
    "# print(f\"1개수: {len(np.where(predictions[:]==1)[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = pd.DataFrame({\"0\":probs[:,0], \"1\":probs[:,1]})\n",
    "# df = pd.DataFrame({\"Probability\":probs[:,1]})\n",
    "\n",
    "# # save_xlsx = pd.ExcelWriter(f\"./RTFACT_Public_Possibility_{CONFIG['model_id']}.xlsx\")\n",
    "# # df.to_excel(save_xlsx, index = False) # xlsx 파일로 변환\n",
    "# # save_xlsx.save() #xlsx 파일로 저장\n",
    "\n",
    "# # ExcelWriter 사용\n",
    "# # with pd.ExcelWriter(f\"../../Submission results/RTFACT_241011_Public_Possibility_{CONFIG['model_id']}_Sigmoid.xlsx\", engine='openpyxl') as writer:\n",
    "# with pd.ExcelWriter(f\"../../Submission results/private/RTFACT_241014_Private_Possibility_{CONFIG['model_id']}_Softmax.xlsx\", engine='openpyxl') as writer:\n",
    "#     df.to_excel(writer, sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 62.5 hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public label\n",
    "testset = PublicTest(\"./dataset/Signal_Test_Private_quarter.h5\")\n",
    "public_test_loader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # collate_fn=lambda x: collate_fn(\n",
    "    #             x, max_len=CONFIG['seq_len']),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "total_loss = []\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, label) in enumerate(tqdm(public_test_loader)):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        label = label.to(device)\n",
    "        # padding_mask = padding_mask.float().to(device)\n",
    "\n",
    "        outputs = exp.swa_model(batch_x, None, None, None)\n",
    "\n",
    "        pred = outputs.detach().cpu()\n",
    "\n",
    "        preds.append(outputs.detach())\n",
    "        trues.append(label)\n",
    "\n",
    "preds = torch.cat(preds, 0)\n",
    "trues = torch.cat(trues, 0)\n",
    "\n",
    "probs = torch.nn.functional.softmax(\n",
    "# probs = torch.nn.functional.sigmoid(\n",
    "    preds\n",
    ")  # (total_samples, num_classes) est. prob. for each class and sample\n",
    "\n",
    "trues_onehot = (torch.nn.functional.one_hot(trues.reshape(-1,).to(torch.long),\n",
    "                num_classes=CONFIG['num_class'],).float().cpu().numpy())\n",
    "\n",
    "print(trues_onehot.shape)\n",
    "predictions = (\n",
    "    torch.argmax(probs, dim=1).cpu().numpy()\n",
    ")  # (total_samples,) int class index for each sample\n",
    "probs = probs.cpu().numpy()\n",
    "trues = trues.flatten().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "f1 = f1_score(trues, predictions, average=\"binary\")\n",
    "auroc = roc_auc_score(trues_onehot, probs)\n",
    "# auroc = roc_auc_score(trues, probs)\n",
    "mcc = matthews_corrcoef(trues, predictions)\n",
    "cpi = (0.25 * f1) + (0.25 * auroc) + (0.5 * mcc)\n",
    "\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"AUROC score: {auroc}\")\n",
    "print(f\"MCC score: {mcc}\")\n",
    "print(f\"CPI score: {cpi}\")\n",
    "print()\n",
    "print(f\"0개수: {len(np.where(predictions[:]==0)[0])}\")\n",
    "print(f\"1개수: {len(np.where(predictions[:]==1)[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"0\":probs[:,0], \"1\":probs[:,1]})\n",
    "df = pd.DataFrame({\"Probability\":probs[:,1]})\n",
    "\n",
    "# save_xlsx = pd.ExcelWriter(f\"./RTFACT_Public_Possibility_{CONFIG['model_id']}.xlsx\")\n",
    "# df.to_excel(save_xlsx, index = False) # xlsx 파일로 변환\n",
    "# save_xlsx.save() #xlsx 파일로 저장\n",
    "\n",
    "# ExcelWriter 사용\n",
    "with pd.ExcelWriter(f\"../../Submission results/private/RTFACT_241014_Private_Possibility_{CONFIG['model_id']}_Softmax.xlsx\", engine='openpyxl') as writer:\n",
    "# with pd.ExcelWriter(f\"../../Submission results/private/RTFACT_241014_Private_Possibility_{CONFIG['model_id']}_Sigmoid.xlsx\", engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
