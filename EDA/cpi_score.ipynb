{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.996589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.070218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.856715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.213359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob  pred\n",
       "0    0.000127     0\n",
       "1    0.000149     0\n",
       "2    0.000181     0\n",
       "3    0.000045     0\n",
       "4    0.000038     0\n",
       "..        ...   ...\n",
       "295  0.996589     1\n",
       "296  0.000034     0\n",
       "297  0.070218     0\n",
       "298  0.856715     1\n",
       "299  0.213359     0\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:\\Git\\Artifact-Detection-In-ECG\\label\\RTFACT_240927_Public_Possibility_S01.xlsx')\n",
    "\n",
    "predict = pd.DataFrame()\n",
    "predict['prob'] = df['1']\n",
    "predict['pred'] = df['label']\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPI Score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 average = `binary`(default) / AUROC average = `macro`(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "nbr = 1000000\n",
    "num_ones = 75\n",
    "num_zeros = 300 - num_ones\n",
    "\n",
    "unique_arrays = set()\n",
    "\n",
    "while len(unique_arrays) < nbr:\n",
    "    array = np.array([1] * num_ones + [0] * num_zeros)\n",
    "    np.random.shuffle(array)\n",
    "    unique_arrays.add(tuple(array))\n",
    "\n",
    "unique_arrays_list = [np.array(arr) for arr in unique_arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [33:12<00:00, 501.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# print(\"F1 score average = binary(default)\")\n",
    "# print(\"AUROC score average = macro(default)\\n\")\n",
    "maybe_true = pd.DataFrame()\n",
    "for idx in tqdm(range(len(unique_arrays_list))):\n",
    "    maybe_true['label'] = unique_arrays_list[idx]\n",
    "    \n",
    "    # F1 Score 계산\n",
    "    f1 = f1_score(maybe_true['label'], predict['pred'])\n",
    "\n",
    "    # AUROC 계산\n",
    "    auroc = roc_auc_score(maybe_true['label'], predict['prob'])\n",
    "\n",
    "    # MCC 계산\n",
    "    mcc = matthews_corrcoef(maybe_true['label'], predict['pred'])\n",
    "\n",
    "    # CPI 계산\n",
    "    cpi = 0.25 * f1 + 0.25 * auroc + 0.5 * mcc\n",
    "\n",
    "    # print(f\"====== CPI estimate ===============\")\n",
    "    # print(f\"- F1 Score: {f1}\")\n",
    "    # print(f\"- AUROC: {auroc}\")\n",
    "    # print(f\"- MCC: {mcc}\")\n",
    "    # print(f\">>> CPI: {cpi}\")\n",
    "\n",
    "    CPI_Score = np.round(cpi,3)\n",
    "    if np.abs(cpi - 0.468) < 0.003:\n",
    "        print(f'idx : {idx}, CPI Score : {CPI_Score}')\n",
    "        maybe_true.to_excel(f\"C:\\Git\\Artifact-Detection-In-ECG\\label\\maybe_true_public_test_label_{idx}.xlsx\")\n",
    "        # print(unique_arrays_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
